---
layout: post
section-type: study-notes
has-comments: true
date: 2025-10-23 00:00:00 +0000
title: Refresh Token는 어디에 보관해야 될까? / LLM은 무엇일까요? 
---

<h5> 스터디 진행 일시</h5>
<blockquote>날짜 : 10월 23일 (목요일)    
시간 : 오후 7시 ~ 9시 (2시간)   
장소 : 강남 (오프라인)
오늘 함께한 멤버 ❣️ : 준호님 / 은지님 / 유경님 / 소영님 / 요한님
</blockquote>

<br>

<h5> 🔧 금주 스터디 일정 </h5>
- 아이스 브레이킹
- LLM은 무엇일까요? (은지님 세미나)
- Refresh Token는 어디에 보관해야 될까?  (준호님 세미나)

<br>  

<h4>LLM은 무엇일까요?</h4>  
🙌 은지님의 세미나 🙌  

<br>  


- **L**arge **L**anguage **M**odel의 약자
    - 대규모 언어 모델  

- LLM은 어떻게 말을 이해 할 수 있는걸까?
    - LLM은 인간처럼 말에 대한 “의미를 이해한다” 라기 보다는 패턴을 확률적으로 예측하는 구조
    - “오늘 날씨가 너무 _____”
    - 다음 단어 후보를 확률적으로 계산
        - 좋다. → 0.75
        - 나쁘다. → 0.15
        - 맛있다.  → 0.02

- **토큰화(Token)과 임베딩 벡터 (embedding)**
    - 문장 : How are you doing?
    - 토큰화 : [”How”, “are”, “you”, “doing” , “?” ]
    - 임베딩 : How → [0.21, -0.56, 0.87, ...],  are → [-0.33, 0.92, ...]  

- LLM은 문맥을 이해하기 위해 모든 단어 쌍의 관계 계산함. 
    - 각 단어(Query) 가 다른 단어(Key) 와 얼마나 관련이 있는지를 확률로 평가.

- 🤷‍♀️ 왜 이렇게 복잡하게 하지 ??
    - LLM 구조의 핵심 철학 → 조합이 아니라 “관계”
    - 단순히 토큰화해서 임베딩을 한 것만 사용하면 **단어의 의미가** 무시될 수 있음

- 🧩 LLM이 단어를 예측하는 과정
    - LLM은 문장을 한 번에 생성하지 않고, **이전 단어들을 참고해 다음 단어를 확률적으로 예측**하는데, 매 시점마다 “다음에 올 가능성이 높은 단어”를 계산해 나가는 방식임.

---

**Step 1**  
입력 문맥: “오늘 기분 어때?”  
예측 후보: 음 / 오늘은 / 글쎄요 / 좋아요  
확률 분포(예시): [0.30, 0.27, 0.23, 0.20]  
→ **선택:** “음”

---

**Step 2**  
입력 문맥: “음”  
예측 후보: 오늘은 / 글쎄요 / 괜찮아요 / 별로예요  
확률 분포(예시): [0.40, 0.30, 0.20, 0.10]  
→ **선택:** “오늘은”

---

**Step 3**  
입력 문맥: “음 오늘은”  
예측 후보: 괜찮아요 / 좋아요 / 피곤해요 / 그냥 그래요  
확률 분포(예시): [0.45, 0.35, 0.15, 0.05]  
→ **선택:** “괜찮아요”

---

**Step 4**  
입력 문맥: “음 오늘은 괜찮아요”  
예측 후보: . / ! / 요 / ~  
확률 분포(예시): [0.70, 0.15, 0.10, 0.05]  
→ **선택:** “.”

---

🗣️ **최종 출력:**  
→ “음 오늘은 괜찮아요.”

이처럼 LLM은 단순히 단어를 나열하는 게 아니라, 매 순간 **가장 자연스러운 확률적 선택**을 통해 문장을 선택함.

<br>

**🤔 Hallucination이 뭘까요?**
- 모델이 사실이 아닌 정보를 “진짜처럼” 생성하는 현상을 말함
- 입력과 상관없는 거짓 정보를 자신 있게 말하는 상황
    - 운동을 하면 치매 예방에 도움이 된다.  
    - 치매를 치료하기 위해선 운동을 해야한다.

**🤷‍♀️ Hallucination은 왜 생길까?**

- LLM은 사실 기반 추론이 아니라, 확률적 언어 생성 모델
    - 확률적으로 문맥상 자연스러운 단어를 선택
    - 질문이 애매하거나 맥락이 부족하면, 모델은 불확실한 상태에서 가장 “가능성 높은 문장”을 말하려고 함
    - 모르면 모른다고 말하는거를 안가르쳤음

**🐧 Hallucination을 줄일려면 어떻게 해야하죠?**
- RAG / temperature / top_p 같이 기술을 도입하거나 파라미터를 수정하여 줄일 수 있음.
- 물론 다 적용해도 할루시네이션은 없어지지 않음
- 여전히 LLM은 확률 기반 모델이기 때문이지만, RAG나 프롬프트, 파라미터를 통해 많이 줄일 수 있음. 

<br>  

<h4>Refresh Token는 어디에 보관해야 될까? </h4>  
🙌 준호님의 세미나 🙌  

<br>  

- 엑세스 토큰과 리프레시 토큰의 만료 시간을 얼마나 잡아야 될까?
    - 엑세스 토큰은 '인증 상태를 빠르게 검증하기 위해 사용하는 단기 토큰' 이므로 만료 시간을 짧게 잡아, 탈취되더라도 피해를 최소화한다. 보통 15분 내외로 잡는 것이 좋다.
    - 리프레시 토큰은 엑세스 토큰이 만료되면 새로 발급해주는 토큰으로, 2주에서 4주 내외로 설정하는 경우가 많다. 

- 그렇다면 리프레시 토큰은 어디에 두는게 좋을까?
    - 엑세스 토큰과 다르게, 리프레시 토큰이 노출되면 매우 위험하다.
    - 서버가 관리하는 쿠키에 두는 것이 가장 안전하다. 

<br>